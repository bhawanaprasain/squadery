{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a346a919",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "Define a variable my_sent to be a list of words <br>\n",
    "\n",
    "Use syntax <br>\n",
    "`my_sent = [\"My\", \"sent\"]` (but with your own words, or a favorite saying). <br>\n",
    "\n",
    "Use `' '.join(my_sent)` to convert this into a string <br>\n",
    "Use `split()` to split the string back into the list form you had to start with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bca5c805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There is a simple way to place text which will not be modified in Jupyter Notebook '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sent = [\"There\", \"is\", \"a\", \"simple\", \"way\", \"to\", \"place\", \"text\", \"which\", \"will\", \"not\", \"be\", \"modified\", \"in\", \"Jupyter\", \"Notebook \"]\n",
    "my_sent = \" \".join(my_sent)\n",
    "my_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d9c9165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There', 'is', 'a', 'simple', 'way', 'to', 'place', 'text', 'which', 'will', 'not', 'be', 'modified', 'in', 'Jupyter', 'Notebook']\n"
     ]
    }
   ],
   "source": [
    "my_sent = my_sent.split()\n",
    "print(my_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae53e36",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Define several variables containing lists of words, e.g., **phrase1, phrase2** and so on. Join them together in various combinations **(using the plus operator)** to form whole sentences. <br> <br> What is the relationship between len(phrase1 + phrase2) and len(phrase1) + len(phrase2)?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77dc5746",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase1 = [\"Rainy\",\"days\",\"are\",\"about\",\"to\",\"come\"]\n",
    "phrase2 = [\"Nowadays\",\"youths\",\"are\",\"active\",\"in\",\"politics\"]\n",
    "phrase3 = [\"Programming\",\"is\",\"all\",\"about\",\"practise\"]\n",
    "phrase4 = [\"I\",\"like\",\"travelling\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33157aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "combination1 = ' '.join(phrase1+phrase2)\n",
    "combination2 = ' '.join(phrase2+phrase1+phrase3)\n",
    "combination3 = ' '.join(phrase2+phrase1+phrase4+phrase3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa3f06f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rainy days are about to come Nowadays youths are active in politics\n",
      "Nowadays youths are active in politics Rainy days are about to come Programming is all about practise\n",
      "Nowadays youths are active in politics Rainy days are about to come I like travelling Programming is all about practise\n"
     ]
    }
   ],
   "source": [
    "print(combination1)\n",
    "print(combination2)\n",
    "print(combination3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84b6cc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(phrase1 + phrase2)  == len(phrase1) + len(phrase2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db051ad9",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "What is the difference between the following two lines? Which one will give a larger value? Will this be the case for other texts?<br>\n",
    "* `sorted(set(w.lower() for w in text1))`\n",
    "* `sorted(w.lower() for w in set(text1))`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe4bde76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['about', 'are', 'come', 'days', 'rainy', 'to']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sorted(set(w.lower() for w in phrase1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b5b32c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['about', 'are', 'come', 'days', 'rainy', 'to']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(w.lower() for w in set(phrase1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a26bef",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "What is the difference between the following two tests? <br>\n",
    "* `w.isupper()`\n",
    "* `not w.islower()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce5a5f7",
   "metadata": {},
   "source": [
    " **Answer**\n",
    " * `w.isupper()` checks whether all characters are in uppercase in a word\n",
    " * `not w.islower()` checks whether there is at least one uppercase character  in a word.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "080bb421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'Water'\n",
    "word.isupper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e13c67b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not word.islower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12f1325",
   "metadata": {},
   "source": [
    "Thus, we can see that `word.isupper()` returns `False` due to presence of one uppercase letter \n",
    "<br>\n",
    "`not w.islower()` returns `True` as one uppercase letter is present"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3d6ac5",
   "metadata": {},
   "source": [
    "# Task 5\n",
    "\n",
    "What does the following Python code do?\n",
    "<br>\n",
    "`sum(len(w) for w in text1)`\n",
    "<br>\n",
    "Can you use it to work out the average word length of a text?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d29860c",
   "metadata": {},
   "source": [
    "## Answer\n",
    "\n",
    "`sum(len(w) for w in text1)` gives the  total number of characters present in the  `text1`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8384ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#when entire text is string space count is also included\n",
    "\n",
    "text1= 'Define several variables containing lists of words and join them together in various combinations'\n",
    "sum(len(w) for w in text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd32058f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#when text is splitted into a list, sum of character of strings are counted excluding space\n",
    "\n",
    "text = text1.split()\n",
    "sum(len(w) for w in text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c126d37",
   "metadata": {},
   "source": [
    "## Calculation of average word length of a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccd6efcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word length is  6.0\n"
     ]
    }
   ],
   "source": [
    "text = text1.split()\n",
    "avg_word_len= sum(len(w) for w in text)/len(text)\n",
    "print(\"Average word length is \", avg_word_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba1eb08",
   "metadata": {},
   "source": [
    "# Task 6\n",
    "\n",
    "\n",
    "Define a function `percent(word, text)` that calculates how often a given word occurs in a text, and expresses the result as a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07bee522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent(word,text):\n",
    "    text= text.split()\n",
    "    frequency= text.count(word)\n",
    "    total_words= len(text)\n",
    "    percentage= (frequency/total_words)*100\n",
    "    return f' {word} covers {percentage} % of the total text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bd9f07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' home covers 15.384615384615385 % of the total text'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent(\"home\",\"I go home twice a year but my brother goes home quite frequently\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a04ed5",
   "metadata": {},
   "source": [
    "# Task 7\n",
    "\n",
    "We have been using sets to store vocabularies. Try the following Python expression: set(sent3) < set(text1). Experiment with this using different arguments to set(). What does it do? Can you think of a practical application for this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d89dc329",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent3= \"I go home twice a year but my brother goes home quite frequently\"\n",
    "text1= 'Define several variables containing lists of words and join them together in various combinations'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56e2e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_unique_word(sent,text1):\n",
    "    return set(sent) < set(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6328f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_unique_word(sent3,text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af67e4d",
   "metadata": {},
   "source": [
    "Set operation returns the unique value out of given iterable . So the given `set(sent) < set(text1)` expression can be used to check if `sent` is subset of `text1` or not.If its true it returns boolean value `True` else `False`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a440c180",
   "metadata": {},
   "source": [
    "## Task 8\n",
    "\n",
    "Create a object called translate which you could look up using words in both German and Spanish in order to get corresponding words in English. What problem might arise with this approach? Can you suggest a way to avoid this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b123ac",
   "metadata": {},
   "source": [
    "### Swadesh \n",
    "\n",
    "Swadesh wordlists, in NLTK consists  of about 200 common words in several languages. The languages are identified using an ISO 639 two-letter code.\n",
    "\n",
    "`['be', 'bg', 'bs', 'ca', 'cs', 'cu', 'de', 'en', 'es', 'fr', 'hr','it',\n",
    "  'la', 'mk', 'nl', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sr', 'sw', 'uk']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb2be472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import swadesh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad4fac31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412\n"
     ]
    }
   ],
   "source": [
    "translate = dict()\n",
    "german_to_eng = swadesh.entries(['de','en'])\n",
    "spanish_to_eng = swadesh.entries(['es','en'])\n",
    "translate.update(dict(german_to_eng))\n",
    "translate.update(dict(spanish_to_eng))\n",
    "print(len(translate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bb73b7",
   "metadata": {},
   "source": [
    "Here, german and spanish are both translated to english lanuage so keys will be unique but values for different keys can be same.412 entries are created in translate object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26a83d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207\n"
     ]
    }
   ],
   "source": [
    "translate = dict()\n",
    "eng_to_german = swadesh.entries(['en','de'])\n",
    "eng_to_spanish = swadesh.entries(['en','es'])\n",
    "translate.update(dict(eng_to_german))\n",
    "translate.update(dict(eng_to_spanish))\n",
    "print(len(translate))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cd8584",
   "metadata": {},
   "source": [
    "Here, english is translated to german in first step and dictionary is updated and in next step we translate english to german, so keys can be same for second step  and  the result of first step of translation. As a result only 207 entries are created in translate object. So different objects are preferable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3e99ab",
   "metadata": {},
   "source": [
    "## Task 9\n",
    "\n",
    "Write a program to find all words that occur at least three times in the **Brown Corpus.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "870a0931",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "286a3d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0831c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_word_by_freq(frequency):\n",
    "    unique_words= set(brown.words())\n",
    "    brown_freq_dist= nltk.FreqDist(brown.words())\n",
    "    words_of_given_freq= [word for word in unique_words if brown_freq_dist[word]>frequency]\n",
    "    return words_of_given_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3d45b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_of_given_freq= filter_word_by_freq(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c21f640",
   "metadata": {},
   "source": [
    "## Task 10\n",
    "\n",
    "Write a function that finds the 50 most frequently occurring words of a text that are not stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2fd7bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def most_frequent_words(number):\n",
    "    freq_distribution=nltk.FreqDist(brown.words(categories='news'))\n",
    "    words= [word for word in freq_distribution]\n",
    "    words= [word.lower() for word in freq_distribution if word.lower()  not in stopwords.words('english') and  word.isalpha()]\n",
    "    return words[:number]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9dd3aa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_words = most_frequent_words(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf49d20d",
   "metadata": {},
   "source": [
    "## Task 11\n",
    "\n",
    "\n",
    "Write a program to print the 50 most frequent **bigrams** (pairs of adjacent words) of a text, omitting bigrams that contain stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e33f3581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_freq_bigrams(n):\n",
    "    brown_words=brown.words(categories='news')\n",
    "    words= [word for word in brown_words]\n",
    "    words_without_stopwords= [word.lower() for word in words if word.lower()  not in stopwords.words('english') and  word.isalpha()]\n",
    "    bigrams = [(a,b) for a,b in nltk.bigrams(words_without_stopwords) ]\n",
    "    bigrams_fd = nltk.FreqDist(bigrams)\n",
    "    return bigrams_fd.most_common(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b60502b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('new', 'york'), 52), (('per', 'cent'), 50), (('united', 'states'), 37), (('last', 'week'), 35), (('last', 'year'), 34), (('white', 'house'), 29), (('high', 'school'), 23), (('home', 'runs'), 23), (('president', 'kennedy'), 20), (('last', 'night'), 18), (('said', 'would'), 15), (('years', 'ago'), 15), (('san', 'francisco'), 15), (('premier', 'khrushchev'), 13), (('kansas', 'city'), 13), (('vice', 'president'), 12), (('los', 'angeles'), 12), (('united', 'nations'), 11), (('new', 'orleans'), 11), (('police', 'said'), 11), (('sales', 'tax'), 10), (('two', 'years'), 10), (('american', 'catholic'), 10), (('mantle', 'maris'), 10), (('jury', 'said'), 9), (('would', 'like'), 9), (('el', 'paso'), 9), (('social', 'security'), 9), (('kennedy', 'administration'), 9), (('first', 'time'), 9), (('country', 'club'), 9), (('rules', 'committee'), 9), (('air', 'force'), 9), (('tax', 'bill'), 9), (('grand', 'jury'), 8), (('city', 'council'), 8), (('rhode', 'island'), 8), (('president', 'said'), 8), (('weeks', 'ago'), 8), (('secretary', 'state'), 8), (('home', 'rule'), 8), (('first', 'two'), 8), (('american', 'league'), 8), (('home', 'run'), 8), (('higher', 'education'), 8), (('collective', 'bargaining'), 8), (('farm', 'equipment'), 8), (('three', 'years'), 7), (('million', 'dollars'), 7), (('attorney', 'general'), 7)]\n"
     ]
    }
   ],
   "source": [
    "print(n_freq_bigrams(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6db501",
   "metadata": {},
   "source": [
    "## Task 12\n",
    "\n",
    "Write a program to create a table of word frequencies by genre, like the one given in 1 for modals. Choose your own words and try to find words whose presence (or absence) is typical of a genre. Discuss your findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c7874032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  comedy      ego    death    money    dance    night marriage     calm  parents politics \n",
      "      adventure        0        0       20       16        7       30        4        6        1        1 \n",
      " belles_lettres        3        4       57       39       16       44       12        6        8       16 \n",
      "      editorial        1        1       21       15        4       16        4        3        6        7 \n",
      "        fiction        0        1       17       19        2       53        1        6        7        4 \n",
      "     government        0        0        2       13        3        8        4        0        0        4 \n",
      "        hobbies        0        1        3       16       10        2        0        0        7        0 \n",
      "          humor       14        2        1        3        1       11        2        0        1        1 \n",
      "        learned        1        3       21       10        0        7       14        3       14       12 \n",
      "           lore        3        1       26       39        5       24       21        2       22        6 \n",
      "        mystery        0        0       18       32        4       29        6        0        3        0 \n",
      "           news        2        0       10       29        6       64       11        2        4        3 \n",
      "       religion        1        0       41        2        0       12        0        1        1        1 \n",
      "        reviews       12        0       13        2       17       34        3        1        0        9 \n",
      "        romance        0        0       12       24        6       54        8        2        6        1 \n",
      "science_fiction        0        0        2        0        1       10        2        2        1        0 \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "cfd = nltk.ConditionalFreqDist((genre,word)for genre in brown.categories() for word in brown.words(categories=genre))\n",
    "# general_words = [\"love\", \"hate\", \"death\", \"life\", \"marriage\", \"work\", \"children\",\"magic\"]\n",
    "general_words = [\"comedy\", \"ego\", \"death\",\"money\", \"dance\", \"night\", \"marriage\", \"calm\", \"parents\",\"politics\"]\n",
    "\n",
    "cfd.tabulate(conditions=brown.categories(), samples=general_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd74b0d",
   "metadata": {},
   "source": [
    "Comedy has no reference to adventure, mystery, science_fiction and romance. While belles_letter has more concern with words like death, money, night."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2a97a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
