{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40f1ce36",
   "metadata": {},
   "source": [
    "## Text Segmentation\n",
    "\n",
    "\n",
    "Text segmentation is the process of dividing written text into meaningful units, such as words, sentences, or topics. When segmentation bounndaries are well defined, text segmentation is simple. But in unstructured data there are no distinct boundaries and segmentation becomes tedious task.\n",
    "<br><br>\n",
    "In this notebook we will be extracting different segments like abstract, methodology, conclusion in a research paper. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98793264",
   "metadata": {},
   "source": [
    "\n",
    "## Reading a pdf file\n",
    "\n",
    "We need preprocessed text before we start segmentation, so we will be extracting text from pdf file first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3534249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d841794",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path='researchpaper.pdf'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3178cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "pdfFileObject = open(file_path, 'rb')\n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObject)\n",
    "count = pdfReader.numPages\n",
    "text = ''\n",
    "for i in range(count):\n",
    "    page = pdfReader.getPage(i)\n",
    "    text += page.extract_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93d79d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text):\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "019fa146",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleantext= text_cleaning(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee11b022",
   "metadata": {},
   "outputs": [],
   "source": [
    "headings =['Introduction','Abstract', 'Methodology', 'Conclusion','References',\"Proposed System\",\"Conclusion and Future Work\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7071e0c9",
   "metadata": {},
   "source": [
    "We need to find how many times a certain heading occurs in a given scientific paper. If it occurs muliple times then we need to find the actual heading start point. If **introduction** appears more than one time then its occurance can be mentioned in other segment of paper like abstract, methodology and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84671f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Introduction', 1),\n",
       " ('Abstract', 1),\n",
       " ('Methodology', 0),\n",
       " ('Conclusion', 1),\n",
       " ('References', 1),\n",
       " ('Proposed System', 3),\n",
       " ('Conclusion and Future Work', 1)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heading_occurance = [(heading,cleantext.count(heading.lower()) )for heading in headings]\n",
    "heading_occurance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72e8418",
   "metadata": {},
   "source": [
    "`find_occurance` function returns indices where a given heading is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b958999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_occurance(heading):\n",
    "    occurance_indices = [word.start() for word in re.finditer(heading, cleantext)]\n",
    "    return occurance_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfb8e72",
   "metadata": {},
   "source": [
    "In order to determine if a given portion of text is start of segment, we need to analyze fews words after the occurance of heading.\n",
    "If there is no new line or if there is presence of punctuation marks like `.?,;` after the heading term or some words , then it can't be the start of text. It should be the only word or phrase  in a  line, to get identified as a heading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b39e62fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_next_word(index,heading):\n",
    "    return cleantext[index:index+len(heading)+10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25b9dff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_topics(headings):\n",
    "    available_headings =[]\n",
    "    headings = [heading.lower()for heading in headings]\n",
    "    start_indices = []\n",
    "    punctuations= string.punctuation \n",
    "    \n",
    "    for heading in headings:\n",
    "        frequency = cleantext.count(heading.lower())\n",
    "        occurance_indices = find_occurance(heading)\n",
    "        if len(occurance_indices) >0:\n",
    "            for index in occurance_indices:\n",
    "                next_words_seq = prob_next_word(index,heading)\n",
    "                immediate_next_word = next_words_seq[len(heading):]\n",
    "\n",
    "                length= len(immediate_next_word.replace(\" \",\"\"))\n",
    "                is_start = (\"\\n\" in next_words_seq) and (punctuations not in next_words_seq)\n",
    "                if is_start:\n",
    "                    start_indices.append(index)\n",
    "                    available_headings.append(heading)\n",
    "    return available_headings,start_indices\n",
    "available_headings,start_indices= available_topics(headings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca89726d",
   "metadata": {},
   "source": [
    "Start of one segment is end for another segment. Inorder to find the ending of a segment, we choose segment whose starting point is nearest to the current segment's  out of all segment's starting points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a2d6ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_higher_index(heading_index,start_indices):\n",
    "    sorted_indices =  sorted(start_indices)\n",
    "    end_index = sorted_indices.index(heading_index)+1\n",
    "    if end_index == len(sorted_indices):\n",
    "        end_index_val = len(cleantext)\n",
    "    else:\n",
    "        end_index_val =  sorted_indices[end_index]\n",
    "    return end_index_val\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77180ce2",
   "metadata": {},
   "source": [
    "For extracting sections like introduction, abstract we need to find its starting point and ending point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae2c3216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_and_end_index(headings,start_indices):\n",
    "    heading_prob_points = []\n",
    "    for heading in available_headings:\n",
    "        \n",
    "        start_index_val = start_indices[available_headings.index(heading)]\n",
    "        end_index_val =nearest_higher_index(start_index_val,start_indices)\n",
    "        print((heading,start_index_val,end_index_val))\n",
    "        heading_prob_points.append((heading,start_index_val,end_index_val))\n",
    "    return heading_prob_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db484e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('introduction', 1249, 5584)\n",
      "('abstract', 330, 1249)\n",
      "('references', 20127, 23531)\n",
      "('proposed system', 5584, 19391)\n",
      "('conclusion and future work', 19391, 20127)\n"
     ]
    }
   ],
   "source": [
    "heading_prob_points= start_and_end_index(headings,start_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1254d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_headings = [\"introduction\",\"abstract\",\"conclusion and future work\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e528d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter heading of your choice abstract\n",
      "abstract\n"
     ]
    }
   ],
   "source": [
    "user_heading = input(\"Enter heading of your choice \")\n",
    "user_heading = user_heading.lower()\n",
    "print(user_heading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "afc71ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABSTRACT\n",
      "\n",
      "in this work, we address the problem\n",
      "of spelling correction in the arabic lan-\n",
      "guage utilizing the new corpus provided\n",
      "by qalb (qatar arabic language bank)\n",
      "project which is an annotated corpus of\n",
      "sentences with errors and their corrections.\n",
      "the corpus contains edit, add before, split,\n",
      "merge, add after, move and other error\n",
      "types. we are concerned with the \u0002rst four\n",
      "error types as they contribute more than\n",
      "90% of the spelling errors in the corpus.\n",
      "the proposed system has many models to\n",
      "address each error type on its own and then\n",
      "integrating all the models to provide an\n",
      "ef\u0002cient and robust system that achieves\n",
      "an overall recall of 0.59, precision of 0.58\n",
      "and f1 score of 0.58 including all the error\n",
      "types on the development set. our system\n",
      "participated in the qalb 2014 shared task\n",
      "ï¬‚automatic arabic error correctionï¬‚ and\n",
      "achieved an f1 score of 0.6, earning the\n",
      "sixth place out of nine participants.\n",
      "1  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if user_heading not in available_headings:\n",
    "    print(\"The heading specified by you not present in research paper\")\n",
    "else:\n",
    "    for heading in available_headings:\n",
    "        index = available_headings.index(heading)\n",
    "        prob_points = heading_prob_points[index]\n",
    "        text = cleantext[prob_points[1]+len(heading):prob_points[2]]\n",
    "        if heading == user_heading:\n",
    "            print(heading.upper())\n",
    "            print(text,\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3294ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e30dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
